{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data and Gathering Initial Thoughts\n",
    "- First thing we see when looking at the dataframe head is the use of commas in seemingly numeric values. Most likely these should be replaced with decimal points. We output the columns with commas in their values and based on the data descriptions file, we can determine these should all be numeric. We string replace the commas to decimal points on those columns and then convert them to floats.  \n",
    "     - From the data descriptions file, we can see that there are more columns that will need to be converted to floats. Any column with 'mean', 'avg', 'price', 'tot', or 'adj' should be numeric. And of the remaining columns, we see that the numeric columns are already in the correct data type. We convert all applicable columns here together.\n",
    "- Next we will quickly check for any duplicates and see that we have none.\n",
    "- When we describe the dataframe, we see that `truck`, `rv`, and `forgntvl` are all numeric columns, but should be treated as categorical when dealing with null value imputation and outliers later on. We may need to convert them back to binary flags for our correlation and modeling later, but for now we will switch them to Y/N flags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('../data/raw/dataset.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Shape:  (100000, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>change_mou</th>\n",
       "      <th>...</th>\n",
       "      <th>forgntvl</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>Customer_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23,9975</td>\n",
       "      <td>219,25</td>\n",
       "      <td>22,5</td>\n",
       "      <td>0,2475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-157,25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>361.0</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57,4925</td>\n",
       "      <td>482,75</td>\n",
       "      <td>37,425</td>\n",
       "      <td>0,2475</td>\n",
       "      <td>22,75</td>\n",
       "      <td>9,1</td>\n",
       "      <td>9,1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>532,25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16,99</td>\n",
       "      <td>10,25</td>\n",
       "      <td>16,99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4,25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>1000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>7,5</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1,5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55,23</td>\n",
       "      <td>570,5</td>\n",
       "      <td>71,98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38,5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  rev_Mean mou_Mean totmrc_Mean da_Mean ovrmou_Mean ovrrev_Mean vceovr_Mean  \\\n",
       "0  23,9975   219,25        22,5  0,2475           0           0           0   \n",
       "1  57,4925   482,75      37,425  0,2475       22,75         9,1         9,1   \n",
       "2    16,99    10,25       16,99       0           0           0           0   \n",
       "3       38      7,5          38       0           0           0           0   \n",
       "4    55,23    570,5       71,98       0           0           0           0   \n",
       "\n",
       "  datovr_Mean roam_Mean change_mou  ... forgntvl ethnic kid0_2 kid3_5 kid6_10  \\\n",
       "0           0         0    -157,25  ...      0.0      N      U      U       U   \n",
       "1           0         0     532,25  ...      0.0      Z      U      U       U   \n",
       "2           0         0      -4,25  ...      0.0      N      U      Y       U   \n",
       "3           0         0       -1,5  ...      0.0      U      Y      U       U   \n",
       "4           0         0       38,5  ...      0.0      I      U      U       U   \n",
       "\n",
       "  kid11_15 kid16_17 creditcd eqpdays Customer_ID  \n",
       "0        U        U        Y   361.0     1000001  \n",
       "1        U        U        Y   240.0     1000002  \n",
       "2        U        U        Y  1504.0     1000003  \n",
       "3        U        U        Y  1812.0     1000004  \n",
       "4        U        U        Y   434.0     1000005  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('DF Shape: ', raw_df.shape)\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 100 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   rev_Mean          99643 non-null   object \n",
      " 1   mou_Mean          99643 non-null   object \n",
      " 2   totmrc_Mean       99643 non-null   object \n",
      " 3   da_Mean           99643 non-null   object \n",
      " 4   ovrmou_Mean       99643 non-null   object \n",
      " 5   ovrrev_Mean       99643 non-null   object \n",
      " 6   vceovr_Mean       99643 non-null   object \n",
      " 7   datovr_Mean       99643 non-null   object \n",
      " 8   roam_Mean         99643 non-null   object \n",
      " 9   change_mou        99109 non-null   object \n",
      " 10  change_rev        99109 non-null   object \n",
      " 11  drop_vce_Mean     100000 non-null  object \n",
      " 12  drop_dat_Mean     100000 non-null  object \n",
      " 13  blck_vce_Mean     100000 non-null  object \n",
      " 14  blck_dat_Mean     100000 non-null  object \n",
      " 15  unan_vce_Mean     100000 non-null  object \n",
      " 16  unan_dat_Mean     100000 non-null  object \n",
      " 17  plcd_vce_Mean     100000 non-null  object \n",
      " 18  plcd_dat_Mean     100000 non-null  object \n",
      " 19  recv_vce_Mean     100000 non-null  object \n",
      " 20  recv_sms_Mean     100000 non-null  object \n",
      " 21  comp_vce_Mean     100000 non-null  object \n",
      " 22  comp_dat_Mean     100000 non-null  object \n",
      " 23  custcare_Mean     100000 non-null  object \n",
      " 24  ccrndmou_Mean     100000 non-null  object \n",
      " 25  cc_mou_Mean       100000 non-null  object \n",
      " 26  inonemin_Mean     100000 non-null  object \n",
      " 27  threeway_Mean     100000 non-null  object \n",
      " 28  mou_cvce_Mean     100000 non-null  object \n",
      " 29  mou_cdat_Mean     100000 non-null  object \n",
      " 30  mou_rvce_Mean     100000 non-null  object \n",
      " 31  owylis_vce_Mean   100000 non-null  object \n",
      " 32  mouowylisv_Mean   100000 non-null  object \n",
      " 33  iwylis_vce_Mean   100000 non-null  object \n",
      " 34  mouiwylisv_Mean   100000 non-null  object \n",
      " 35  peak_vce_Mean     100000 non-null  object \n",
      " 36  peak_dat_Mean     100000 non-null  object \n",
      " 37  mou_peav_Mean     100000 non-null  object \n",
      " 38  mou_pead_Mean     100000 non-null  object \n",
      " 39  opk_vce_Mean      100000 non-null  object \n",
      " 40  opk_dat_Mean      100000 non-null  object \n",
      " 41  mou_opkv_Mean     100000 non-null  object \n",
      " 42  mou_opkd_Mean     100000 non-null  object \n",
      " 43  drop_blk_Mean     100000 non-null  object \n",
      " 44  attempt_Mean      100000 non-null  object \n",
      " 45  complete_Mean     100000 non-null  object \n",
      " 46  callfwdv_Mean     100000 non-null  object \n",
      " 47  callwait_Mean     100000 non-null  object \n",
      " 48  churn             100000 non-null  int64  \n",
      " 49  months            100000 non-null  int64  \n",
      " 50  uniqsubs          100000 non-null  int64  \n",
      " 51  actvsubs          100000 non-null  int64  \n",
      " 52  new_cell          100000 non-null  object \n",
      " 53  crclscod          100000 non-null  object \n",
      " 54  asl_flag          100000 non-null  object \n",
      " 55  totcalls          100000 non-null  int64  \n",
      " 56  totmou            100000 non-null  object \n",
      " 57  totrev            100000 non-null  object \n",
      " 58  adjrev            100000 non-null  object \n",
      " 59  adjmou            100000 non-null  object \n",
      " 60  adjqty            100000 non-null  int64  \n",
      " 61  avgrev            100000 non-null  object \n",
      " 62  avgmou            100000 non-null  object \n",
      " 63  avgqty            100000 non-null  object \n",
      " 64  avg3mou           100000 non-null  int64  \n",
      " 65  avg3qty           100000 non-null  int64  \n",
      " 66  avg3rev           100000 non-null  int64  \n",
      " 67  avg6mou           97161 non-null   float64\n",
      " 68  avg6qty           97161 non-null   float64\n",
      " 69  avg6rev           97161 non-null   float64\n",
      " 70  prizm_social_one  92612 non-null   object \n",
      " 71  area              99960 non-null   object \n",
      " 72  dualband          99999 non-null   object \n",
      " 73  refurb_new        99999 non-null   object \n",
      " 74  hnd_price         99153 non-null   object \n",
      " 75  phones            99999 non-null   float64\n",
      " 76  models            99999 non-null   float64\n",
      " 77  hnd_webcap        89811 non-null   object \n",
      " 78  truck             98268 non-null   float64\n",
      " 79  rv                98268 non-null   float64\n",
      " 80  ownrent           66294 non-null   object \n",
      " 81  lor               69810 non-null   float64\n",
      " 82  dwlltype          68091 non-null   object \n",
      " 83  marital           98268 non-null   object \n",
      " 84  adults            76981 non-null   float64\n",
      " 85  infobase          77921 non-null   object \n",
      " 86  income            74564 non-null   float64\n",
      " 87  numbcars          50634 non-null   float64\n",
      " 88  HHstatin          62077 non-null   object \n",
      " 89  dwllsize          61692 non-null   object \n",
      " 90  forgntvl          98268 non-null   float64\n",
      " 91  ethnic            98268 non-null   object \n",
      " 92  kid0_2            98268 non-null   object \n",
      " 93  kid3_5            98268 non-null   object \n",
      " 94  kid6_10           98268 non-null   object \n",
      " 95  kid11_15          98268 non-null   object \n",
      " 96  kid16_17          98268 non-null   object \n",
      " 97  creditcd          98268 non-null   object \n",
      " 98  eqpdays           99999 non-null   float64\n",
      " 99  Customer_ID       100000 non-null  int64  \n",
      "dtypes: float64(13), int64(10), object(77)\n",
      "memory usage: 76.3+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.42969\n"
     ]
    }
   ],
   "source": [
    "# percentage of null values\n",
    "\n",
    "print(((raw_df.isnull().sum().sum()) / (raw_df.shape[0] * raw_df.shape[1])) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with commas:  ['rev_Mean', 'mou_Mean', 'totmrc_Mean', 'da_Mean', 'ovrmou_Mean', 'ovrrev_Mean', 'vceovr_Mean', 'datovr_Mean', 'roam_Mean', 'change_mou', 'change_rev', 'drop_vce_Mean', 'drop_dat_Mean', 'blck_vce_Mean', 'blck_dat_Mean', 'unan_vce_Mean', 'unan_dat_Mean', 'plcd_vce_Mean', 'plcd_dat_Mean', 'recv_vce_Mean', 'recv_sms_Mean', 'comp_vce_Mean', 'comp_dat_Mean', 'custcare_Mean', 'ccrndmou_Mean', 'cc_mou_Mean', 'inonemin_Mean', 'threeway_Mean', 'mou_cvce_Mean', 'mou_cdat_Mean', 'mou_rvce_Mean', 'owylis_vce_Mean', 'mouowylisv_Mean', 'iwylis_vce_Mean', 'mouiwylisv_Mean', 'peak_vce_Mean', 'peak_dat_Mean', 'mou_peav_Mean', 'mou_pead_Mean', 'opk_vce_Mean', 'opk_dat_Mean', 'mou_opkv_Mean', 'mou_opkd_Mean', 'drop_blk_Mean', 'attempt_Mean', 'complete_Mean', 'callfwdv_Mean', 'callwait_Mean', 'totmou', 'totrev', 'adjrev', 'adjmou', 'avgrev', 'avgmou', 'avgqty', 'hnd_price']\n",
      "Data Types:  [dtype('O')]\n"
     ]
    }
   ],
   "source": [
    "# finding cols with commas and their data types\n",
    "\n",
    "test_df = raw_df.map(str)\n",
    "contains_comma = test_df.apply(lambda x: x.str.contains(','), axis=0).any()\n",
    "columns_with_comma = contains_comma[contains_comma].index.tolist()\n",
    "\n",
    "print('Columns with commas: ', columns_with_comma)\n",
    "\n",
    "print('Data Types: ', raw_df[columns_with_comma].dtypes.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string replace ',' --> '.' \n",
    "\n",
    "decimal_df = raw_df.copy()\n",
    "\n",
    "for col in columns_with_comma:\n",
    "    if decimal_df[col].dtype == 'object':\n",
    "        decimal_df[col] = decimal_df[col].astype(str)\n",
    "        decimal_df[col] = decimal_df[col].str.replace(',', '.', regex=False)\n",
    "\n",
    "decimal_df[columns_with_comma] = decimal_df[columns_with_comma].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Customer_ID', 'HHstatin', 'actvsubs', 'adults', 'area', 'asl_flag',\n",
      "       'churn', 'crclscod', 'creditcd', 'dualband', 'dwllsize', 'dwlltype',\n",
      "       'eqpdays', 'ethnic', 'forgntvl', 'hnd_webcap', 'income', 'infobase',\n",
      "       'kid0_2', 'kid11_15', 'kid16_17', 'kid3_5', 'kid6_10', 'lor', 'marital',\n",
      "       'models', 'months', 'new_cell', 'numbcars', 'ownrent', 'phones',\n",
      "       'prizm_social_one', 'refurb_new', 'rv', 'truck', 'uniqsubs'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# get numeric cols\n",
    "\n",
    "str_num_cols = [col for col in decimal_df.columns if any(substring in col.lower() for substring in ['mean', 'avg', 'price', 'tot', 'adj'])]\n",
    "\n",
    "remaining_cols = decimal_df.columns.difference(columns_with_comma + str_num_cols)\n",
    "\n",
    "print(remaining_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numeric cols\n",
    "\n",
    "numeric_df = decimal_df.copy()\n",
    "\n",
    "num_cols = list(set(columns_with_comma + str_num_cols))\n",
    "\n",
    "numeric_df[num_cols] = numeric_df[num_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any duplicate rows\n",
    "\n",
    "numeric_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>change_mou</th>\n",
       "      <th>...</th>\n",
       "      <th>models</th>\n",
       "      <th>truck</th>\n",
       "      <th>rv</th>\n",
       "      <th>lor</th>\n",
       "      <th>adults</th>\n",
       "      <th>income</th>\n",
       "      <th>numbcars</th>\n",
       "      <th>forgntvl</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>Customer_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99643.000000</td>\n",
       "      <td>99109.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>98268.000000</td>\n",
       "      <td>98268.000000</td>\n",
       "      <td>69810.000000</td>\n",
       "      <td>76981.000000</td>\n",
       "      <td>74564.000000</td>\n",
       "      <td>50634.000000</td>\n",
       "      <td>98268.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>58.719985</td>\n",
       "      <td>513.559937</td>\n",
       "      <td>46.179136</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>41.072247</td>\n",
       "      <td>13.559560</td>\n",
       "      <td>13.295062</td>\n",
       "      <td>0.261318</td>\n",
       "      <td>1.286405</td>\n",
       "      <td>-13.933818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.545825</td>\n",
       "      <td>0.188820</td>\n",
       "      <td>0.082580</td>\n",
       "      <td>6.177238</td>\n",
       "      <td>2.530326</td>\n",
       "      <td>5.783112</td>\n",
       "      <td>1.567563</td>\n",
       "      <td>0.057974</td>\n",
       "      <td>391.932309</td>\n",
       "      <td>1.050000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46.291677</td>\n",
       "      <td>525.168140</td>\n",
       "      <td>23.623489</td>\n",
       "      <td>2.177619</td>\n",
       "      <td>97.296150</td>\n",
       "      <td>30.500885</td>\n",
       "      <td>30.056089</td>\n",
       "      <td>3.126531</td>\n",
       "      <td>14.711374</td>\n",
       "      <td>276.087509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898395</td>\n",
       "      <td>0.391368</td>\n",
       "      <td>0.275248</td>\n",
       "      <td>4.735267</td>\n",
       "      <td>1.452819</td>\n",
       "      <td>2.182132</td>\n",
       "      <td>0.625456</td>\n",
       "      <td>0.233696</td>\n",
       "      <td>256.482193</td>\n",
       "      <td>2.886766e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.167500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-26.915000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3875.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1.000001e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.260000</td>\n",
       "      <td>150.750000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-87.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>1.025001e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.195000</td>\n",
       "      <td>355.500000</td>\n",
       "      <td>44.990000</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>1.050000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.750000</td>\n",
       "      <td>703.000000</td>\n",
       "      <td>59.990000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>14.437500</td>\n",
       "      <td>14.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>1.075000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3843.262500</td>\n",
       "      <td>12206.750000</td>\n",
       "      <td>409.990000</td>\n",
       "      <td>159.390000</td>\n",
       "      <td>4320.750000</td>\n",
       "      <td>1102.400000</td>\n",
       "      <td>896.087500</td>\n",
       "      <td>423.540000</td>\n",
       "      <td>3685.200000</td>\n",
       "      <td>31219.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1823.000000</td>\n",
       "      <td>1.100000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rev_Mean      mou_Mean   totmrc_Mean       da_Mean   ovrmou_Mean  \\\n",
       "count  99643.000000  99643.000000  99643.000000  99643.000000  99643.000000   \n",
       "mean      58.719985    513.559937     46.179136      0.888828     41.072247   \n",
       "std       46.291677    525.168140     23.623489      2.177619     97.296150   \n",
       "min       -6.167500      0.000000    -26.915000      0.000000      0.000000   \n",
       "25%       33.260000    150.750000     30.000000      0.000000      0.000000   \n",
       "50%       48.195000    355.500000     44.990000      0.247500      2.750000   \n",
       "75%       70.750000    703.000000     59.990000      0.990000     42.000000   \n",
       "max     3843.262500  12206.750000    409.990000    159.390000   4320.750000   \n",
       "\n",
       "        ovrrev_Mean   vceovr_Mean   datovr_Mean     roam_Mean    change_mou  \\\n",
       "count  99643.000000  99643.000000  99643.000000  99643.000000  99109.000000   \n",
       "mean      13.559560     13.295062      0.261318      1.286405    -13.933818   \n",
       "std       30.500885     30.056089      3.126531     14.711374    276.087509   \n",
       "min        0.000000      0.000000      0.000000      0.000000  -3875.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000    -87.000000   \n",
       "50%        1.000000      0.682500      0.000000      0.000000     -6.250000   \n",
       "75%       14.437500     14.025000      0.000000      0.235000     63.000000   \n",
       "max     1102.400000    896.087500    423.540000   3685.200000  31219.250000   \n",
       "\n",
       "       ...        models         truck            rv           lor  \\\n",
       "count  ...  99999.000000  98268.000000  98268.000000  69810.000000   \n",
       "mean   ...      1.545825      0.188820      0.082580      6.177238   \n",
       "std    ...      0.898395      0.391368      0.275248      4.735267   \n",
       "min    ...      1.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      1.000000      0.000000      0.000000      2.000000   \n",
       "50%    ...      1.000000      0.000000      0.000000      5.000000   \n",
       "75%    ...      2.000000      0.000000      0.000000      9.000000   \n",
       "max    ...     16.000000      1.000000      1.000000     15.000000   \n",
       "\n",
       "             adults        income      numbcars      forgntvl       eqpdays  \\\n",
       "count  76981.000000  74564.000000  50634.000000  98268.000000  99999.000000   \n",
       "mean       2.530326      5.783112      1.567563      0.057974    391.932309   \n",
       "std        1.452819      2.182132      0.625456      0.233696    256.482193   \n",
       "min        1.000000      1.000000      1.000000      0.000000     -5.000000   \n",
       "25%        1.000000      4.000000      1.000000      0.000000    212.000000   \n",
       "50%        2.000000      6.000000      1.000000      0.000000    342.000000   \n",
       "75%        3.000000      7.000000      2.000000      0.000000    530.000000   \n",
       "max        6.000000      9.000000      3.000000      1.000000   1823.000000   \n",
       "\n",
       "        Customer_ID  \n",
       "count  1.000000e+05  \n",
       "mean   1.050000e+06  \n",
       "std    2.886766e+04  \n",
       "min    1.000001e+06  \n",
       "25%    1.025001e+06  \n",
       "50%    1.050000e+06  \n",
       "75%    1.075000e+06  \n",
       "max    1.100000e+06  \n",
       "\n",
       "[8 rows x 79 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df[['truck', 'rv', 'forgntvl']] = numeric_df[['truck', 'rv', 'forgntvl']].replace({1.0: 'Y', 0.0: 'N'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Null Values \n",
    "\n",
    "- We check for null values. We see from the info output that many of the features have some null values. We find the features with the highest null percentage are `numbcars`, `dwllsize`, `HHstatin`, `ownrent`, and `dwlltype`.\n",
    "- Almost half of the values in `numbcars` are null. Since the company is in the telecommunications sector, we most likely do not need this variable because we can pick up on information such as income and number of adults in other features. Therefore, we will go ahead and drop this feature. \n",
    "- `dwllsize`, `HHstatin`, and `ownrent` all have over a third of their values being null. We can start by imputing the null values of `dwllsize` with the corresponding average size of `dwlltype`. Although, since `dwlltype` also is in the top five features with the most null values, this most likely will not improve `dwllsize` greatly. It handles ~6k records, so we still need to impute another way. For the remaining null values, we are going to impute them with the average amongst the most common factors for a house size: `income`, `area`, and `num_ppl_household`. The final feature is created by summing `adults`, `kid0_2`, `kid3_5`, `kid6_10`, `kid11_15`, and `kid16_17`. \n",
    "- `HHstatin` is a Premier household status indicator. Since we have other indicators for income and revenue for the customer, we will drop this feature. \n",
    "- We will use the same imputing logic that we used for `dwllsize` for `ownrent`. \n",
    "- For `dwlltype`, we will take the average value from `dwllsize`. \n",
    "- For the remaining features, we will impute with the mode or average, depending on data type. We do this since we will be trying regression models as part of our prediction modeling efforts, so we will not be able to include any null values in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numbcars      49.37\n",
       "dwllsize      38.31\n",
       "HHstatin      37.92\n",
       "ownrent       33.71\n",
       "dwlltype      31.91\n",
       "lor           30.19\n",
       "income        25.44\n",
       "adults        23.02\n",
       "infobase      22.08\n",
       "hnd_webcap    10.19\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the top features with most null\n",
    "\n",
    "null_percentages = (numeric_df.isnull().mean() * 100).round(2).sort_values(ascending=False)\n",
    "\n",
    "null_percentages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features\n",
    "\n",
    "null_df = numeric_df.drop(columns=['numbcars', 'HHstatin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining dwllsize nulls:  31909\n"
     ]
    }
   ],
   "source": [
    "# fill dwllsize with avg dwlltype\n",
    "\n",
    "def mode_fillna(group):\n",
    "    mode_value = group.mode().iloc[0] \n",
    "    return group.fillna(mode_value) \n",
    "\n",
    "null_df['dwllsize'] = null_df.groupby('dwlltype')['dwllsize'].apply(mode_fillna).reset_index(drop=True)\n",
    "\n",
    "print('Remaining dwllsize nulls: ', null_df['dwllsize'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create num ppl feature\n",
    "\n",
    "null_df['num_ppl_household'] = (null_df[['kid0_2', 'kid3_5', 'kid6_10', 'kid11_15', 'kid16_17']] == 'Y').sum(axis=1) + null_df['adults']\n",
    "\n",
    "mask = pd.notnull(null_df['num_ppl_household'])\n",
    "null_df.loc[mask, 'num_ppl_household'] = null_df.loc[mask, 'num_ppl_household'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.notnull(null_df['income'])\n",
    "null_df.loc[mask, 'income'] = null_df.loc[mask, 'income'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining dwllsize nulls:  73\n"
     ]
    }
   ],
   "source": [
    "# fill dwllsize with avg across income, area, num_ppl_household\n",
    "\n",
    "null_df[['income', 'area', 'num_ppl_household']] = null_df[['income', 'area', 'num_ppl_household']].fillna('NaN')\n",
    "\n",
    "def mode_default(x):\n",
    "    mode_values = x.mode()\n",
    "    return mode_values.iat[0] if not mode_values.empty else None\n",
    "\n",
    "mode_mapping = null_df.groupby(['income', 'area', 'num_ppl_household'])['dwllsize'].agg(mode_default).to_dict()\n",
    "null_df['dwllsize'] = null_df.apply(lambda x: mode_mapping[(x['income'], x['area'], x['num_ppl_household'])] if pd.isnull(x['dwllsize']) else x['dwllsize'], axis=1)\n",
    "\n",
    "null_df[['income', 'area', 'num_ppl_household']] = null_df[['income', 'area', 'num_ppl_household']].replace('NaN', np.nan)\n",
    "\n",
    "print('Remaining dwllsize nulls: ', null_df['dwllsize'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining ownrent nulls:  1117\n"
     ]
    }
   ],
   "source": [
    "# fill ownrent with avg across income, area, num_ppl_household\n",
    "\n",
    "null_df[['income', 'area', 'num_ppl_household']] = null_df[['income', 'area', 'num_ppl_household']].fillna('NaN')\n",
    "\n",
    "def mode_default(x):\n",
    "    mode_values = x.mode()\n",
    "    return mode_values.iat[0] if not mode_values.empty else None\n",
    "\n",
    "mode_mapping = null_df.groupby(['income', 'area', 'num_ppl_household'])['ownrent'].agg(mode_default).to_dict()\n",
    "null_df['ownrent'] = null_df.apply(lambda x: mode_mapping[(x['income'], x['area'], x['num_ppl_household'])] if pd.isnull(x['ownrent']) else x['ownrent'], axis=1)\n",
    "\n",
    "null_df[['income', 'area', 'num_ppl_household']] = null_df[['income', 'area', 'num_ppl_household']].replace('NaN', np.nan)\n",
    "\n",
    "print('Remaining ownrent nulls: ', null_df['ownrent'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining ownrent nulls:  9\n"
     ]
    }
   ],
   "source": [
    "# fill ownrent with avg across income, area\n",
    "\n",
    "null_df[['income', 'area']] = null_df[['income', 'area']].fillna('NaN')\n",
    "\n",
    "def mode_default(x):\n",
    "    mode_values = x.mode()\n",
    "    return mode_values.iat[0] if not mode_values.empty else None\n",
    "\n",
    "mode_mapping = null_df.groupby(['income', 'area'])['ownrent'].agg(mode_default).to_dict()\n",
    "null_df['ownrent'] = null_df.apply(lambda x: mode_mapping[(x['income'], x['area'])] if pd.isnull(x['ownrent']) else x['ownrent'], axis=1)\n",
    "\n",
    "null_df[['income', 'area']] = null_df[['income', 'area']].replace('NaN', np.nan)\n",
    "\n",
    "print('Remaining ownrent nulls: ', null_df['ownrent'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining dwlltype nulls:  73\n"
     ]
    }
   ],
   "source": [
    "# fill dwlltype with avg dwllsize\n",
    "\n",
    "def mode_fillna(group):\n",
    "    mode_value = group.mode().iloc[0] \n",
    "    return group.fillna(mode_value) \n",
    "\n",
    "null_df['dwlltype'] = null_df.groupby('dwllsize')['dwlltype'].apply(mode_fillna).reset_index(drop=True)\n",
    "\n",
    "print('Remaining dwlltype nulls: ', null_df['dwlltype'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total remaining nulls:  0\n"
     ]
    }
   ],
   "source": [
    "# impute remaining missing vals with avg / mode\n",
    "\n",
    "numeric_cols = [col for col in null_df.columns if null_df[col].dtype in ['int64', 'float64']]\n",
    "cat_cols = [col for col in null_df.columns if col not in numeric_cols]\n",
    "\n",
    "for col in numeric_cols:\n",
    "    null_df[col].fillna(null_df[col].mean(), inplace=True)\n",
    "\n",
    "for col in cat_cols:\n",
    "    null_df[col].fillna(null_df[col].mode()[0], inplace=True)\n",
    "\n",
    "print('Total remaining nulls: ', null_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df['num_ppl_household'] = null_df['num_ppl_household'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Outliers\n",
    "- All the columns aside from `churn` and `Customer_ID` have outliers. Many of the features with too many outliers to simply drop them from the dataset without greatly impacting our data. \n",
    "- One option could be binning the values to reduce outliers. However, we want to try and keep these variables as numeric for modeling purposes later. Also, a technique like capping or trimming would help eliminate the outliers, but we should be hesitant to completely remove outlier data without having a deep understanding of the company and their industry.\n",
    "- We try a simple linear regression for outlier imputation. While many features are now resolved, others seem to still have been imputed with outlier data. Therefore, we try a more sophisticated method in KNN outlier imputation. \n",
    "- KNN imputation did not solve our outlier issue. Because there are so many of them and the imputation techniques are not resolving them, we will move forward and keep this in mind for modeling. Something like scaling could be used to help the outliers, or models that are more robust and less sensitive to outliers. We will explore this later in the modeling section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Number of Outliers</th>\n",
       "      <th>Outlier Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>change_rev</td>\n",
       "      <td>26325</td>\n",
       "      <td>26.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>roam_Mean</td>\n",
       "      <td>18736</td>\n",
       "      <td>18.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plcd_dat_Mean</td>\n",
       "      <td>14980</td>\n",
       "      <td>14.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>callwait_Mean</td>\n",
       "      <td>14305</td>\n",
       "      <td>14.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cc_mou_Mean</td>\n",
       "      <td>14265</td>\n",
       "      <td>14.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>recv_sms_Mean</td>\n",
       "      <td>872</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>callfwdv_Mean</td>\n",
       "      <td>433</td>\n",
       "      <td>0.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>hnd_price</td>\n",
       "      <td>254</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>churn</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Customer_ID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Number of Outliers  Outlier Percentage\n",
       "10     change_rev               26325              26.325\n",
       "8       roam_Mean               18736              18.736\n",
       "18  plcd_dat_Mean               14980              14.980\n",
       "47  callwait_Mean               14305              14.305\n",
       "25    cc_mou_Mean               14265              14.265\n",
       "..            ...                 ...                 ...\n",
       "20  recv_sms_Mean                 872               0.872\n",
       "46  callfwdv_Mean                 433               0.433\n",
       "67      hnd_price                 254               0.254\n",
       "48          churn                   0               0.000\n",
       "74    Customer_ID                   0               0.000\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determining columns with most outliers\n",
    "\n",
    "def count_outliers(df, numeric_columns):\n",
    "    outliers_count = {}\n",
    "    for column in numeric_columns:\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        outliers_count[column] = df[(df[column] < lower_bound) | (df[column] > upper_bound)].shape[0]\n",
    "    \n",
    "    outliers_df = pd.DataFrame(list(outliers_count.items()), columns=['Feature', 'Number of Outliers']).sort_values(by='Number of Outliers', ascending=False)\n",
    "    outliers_df['Outlier Percentage'] = outliers_df['Number of Outliers'] / (len(null_df)) * 100\n",
    "\n",
    "    return outliers_df\n",
    "\n",
    "outliers_table = count_outliers(null_df, numeric_cols)\n",
    "\n",
    "outliers_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Number of Outliers</th>\n",
       "      <th>Outlier Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>change_rev</td>\n",
       "      <td>26325</td>\n",
       "      <td>26.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>roam_Mean</td>\n",
       "      <td>18736</td>\n",
       "      <td>18.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plcd_dat_Mean</td>\n",
       "      <td>14980</td>\n",
       "      <td>14.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>callwait_Mean</td>\n",
       "      <td>14305</td>\n",
       "      <td>14.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cc_mou_Mean</td>\n",
       "      <td>14265</td>\n",
       "      <td>14.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datovr_Mean</td>\n",
       "      <td>14030</td>\n",
       "      <td>14.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>change_mou</td>\n",
       "      <td>13768</td>\n",
       "      <td>13.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ccrndmou_Mean</td>\n",
       "      <td>13456</td>\n",
       "      <td>13.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mou_cdat_Mean</td>\n",
       "      <td>13393</td>\n",
       "      <td>13.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>comp_dat_Mean</td>\n",
       "      <td>13393</td>\n",
       "      <td>13.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>custcare_Mean</td>\n",
       "      <td>12710</td>\n",
       "      <td>12.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>da_Mean</td>\n",
       "      <td>11994</td>\n",
       "      <td>11.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vceovr_Mean</td>\n",
       "      <td>11601</td>\n",
       "      <td>11.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ovrmou_Mean</td>\n",
       "      <td>11527</td>\n",
       "      <td>11.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ovrrev_Mean</td>\n",
       "      <td>11386</td>\n",
       "      <td>11.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mouiwylisv_Mean</td>\n",
       "      <td>11316</td>\n",
       "      <td>11.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blck_vce_Mean</td>\n",
       "      <td>10701</td>\n",
       "      <td>10.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>iwylis_vce_Mean</td>\n",
       "      <td>10363</td>\n",
       "      <td>10.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mou_opkd_Mean</td>\n",
       "      <td>9618</td>\n",
       "      <td>9.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>opk_dat_Mean</td>\n",
       "      <td>9606</td>\n",
       "      <td>9.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>lor</td>\n",
       "      <td>9399</td>\n",
       "      <td>9.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>adults</td>\n",
       "      <td>9167</td>\n",
       "      <td>9.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>peak_dat_Mean</td>\n",
       "      <td>8942</td>\n",
       "      <td>8.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>mou_pead_Mean</td>\n",
       "      <td>8940</td>\n",
       "      <td>8.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>threeway_Mean</td>\n",
       "      <td>8660</td>\n",
       "      <td>8.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>phones</td>\n",
       "      <td>8411</td>\n",
       "      <td>8.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mouowylisv_Mean</td>\n",
       "      <td>8384</td>\n",
       "      <td>8.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mou_opkv_Mean</td>\n",
       "      <td>8304</td>\n",
       "      <td>8.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>inonemin_Mean</td>\n",
       "      <td>8151</td>\n",
       "      <td>8.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>drop_blk_Mean</td>\n",
       "      <td>7613</td>\n",
       "      <td>7.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mou_rvce_Mean</td>\n",
       "      <td>7201</td>\n",
       "      <td>7.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>drop_vce_Mean</td>\n",
       "      <td>7143</td>\n",
       "      <td>7.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>opk_vce_Mean</td>\n",
       "      <td>7142</td>\n",
       "      <td>7.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>adjqty</td>\n",
       "      <td>7114</td>\n",
       "      <td>7.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>totcalls</td>\n",
       "      <td>7114</td>\n",
       "      <td>7.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>recv_vce_Mean</td>\n",
       "      <td>6997</td>\n",
       "      <td>6.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>unan_vce_Mean</td>\n",
       "      <td>6857</td>\n",
       "      <td>6.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>owylis_vce_Mean</td>\n",
       "      <td>6660</td>\n",
       "      <td>6.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>avg3rev</td>\n",
       "      <td>6160</td>\n",
       "      <td>6.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rev_Mean</td>\n",
       "      <td>6030</td>\n",
       "      <td>6.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>totmou</td>\n",
       "      <td>5987</td>\n",
       "      <td>5.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>adjmou</td>\n",
       "      <td>5979</td>\n",
       "      <td>5.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mou_peav_Mean</td>\n",
       "      <td>5869</td>\n",
       "      <td>5.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mou_cvce_Mean</td>\n",
       "      <td>5821</td>\n",
       "      <td>5.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>avg6rev</td>\n",
       "      <td>5776</td>\n",
       "      <td>5.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>totrev</td>\n",
       "      <td>5684</td>\n",
       "      <td>5.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>adjrev</td>\n",
       "      <td>5646</td>\n",
       "      <td>5.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>avg6qty</td>\n",
       "      <td>5606</td>\n",
       "      <td>5.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>peak_vce_Mean</td>\n",
       "      <td>5471</td>\n",
       "      <td>5.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>avg3qty</td>\n",
       "      <td>5385</td>\n",
       "      <td>5.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Feature  Number of Outliers  Outlier Percentage\n",
       "10       change_rev               26325              26.325\n",
       "8         roam_Mean               18736              18.736\n",
       "18    plcd_dat_Mean               14980              14.980\n",
       "47    callwait_Mean               14305              14.305\n",
       "25      cc_mou_Mean               14265              14.265\n",
       "7       datovr_Mean               14030              14.030\n",
       "9        change_mou               13768              13.768\n",
       "24    ccrndmou_Mean               13456              13.456\n",
       "29    mou_cdat_Mean               13393              13.393\n",
       "22    comp_dat_Mean               13393              13.393\n",
       "23    custcare_Mean               12710              12.710\n",
       "3           da_Mean               11994              11.994\n",
       "6       vceovr_Mean               11601              11.601\n",
       "4       ovrmou_Mean               11527              11.527\n",
       "5       ovrrev_Mean               11386              11.386\n",
       "34  mouiwylisv_Mean               11316              11.316\n",
       "13    blck_vce_Mean               10701              10.701\n",
       "33  iwylis_vce_Mean               10363              10.363\n",
       "42    mou_opkd_Mean                9618               9.618\n",
       "40     opk_dat_Mean                9606               9.606\n",
       "70              lor                9399               9.399\n",
       "71           adults                9167               9.167\n",
       "36    peak_dat_Mean                8942               8.942\n",
       "38    mou_pead_Mean                8940               8.940\n",
       "27    threeway_Mean                8660               8.660\n",
       "68           phones                8411               8.411\n",
       "32  mouowylisv_Mean                8384               8.384\n",
       "41    mou_opkv_Mean                8304               8.304\n",
       "26    inonemin_Mean                8151               8.151\n",
       "43    drop_blk_Mean                7613               7.613\n",
       "30    mou_rvce_Mean                7201               7.201\n",
       "11    drop_vce_Mean                7143               7.143\n",
       "39     opk_vce_Mean                7142               7.142\n",
       "57           adjqty                7114               7.114\n",
       "52         totcalls                7114               7.114\n",
       "19    recv_vce_Mean                6997               6.997\n",
       "15    unan_vce_Mean                6857               6.857\n",
       "31  owylis_vce_Mean                6660               6.660\n",
       "63          avg3rev                6160               6.160\n",
       "0          rev_Mean                6030               6.030\n",
       "53           totmou                5987               5.987\n",
       "56           adjmou                5979               5.979\n",
       "37    mou_peav_Mean                5869               5.869\n",
       "28    mou_cvce_Mean                5821               5.821\n",
       "66          avg6rev                5776               5.776\n",
       "54           totrev                5684               5.684\n",
       "55           adjrev                5646               5.646\n",
       "65          avg6qty                5606               5.606\n",
       "35    peak_vce_Mean                5471               5.471\n",
       "62          avg3qty                5385               5.385"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = outliers_table.head(50)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression outlier imputation \n",
    "\n",
    "def regression_impute(series):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    non_outliers = series[(series >= lower_bound) & (series <= upper_bound)]\n",
    "    X_train = non_outliers.index.to_numpy().reshape(-1, 1)\n",
    "    y_train = non_outliers.to_numpy().reshape(-1, 1)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
    "\n",
    "    if outliers.empty:\n",
    "        return series\n",
    "    \n",
    "    X_outliers = outliers.index.to_numpy().reshape(-1, 1)\n",
    "    y_pred = model.predict(X_outliers)\n",
    "\n",
    "    series.loc[X_outliers.flatten()] = y_pred.flatten()\n",
    "    \n",
    "    return series\n",
    "\n",
    "outliers_df = null_df.copy()\n",
    "outliers_df[numeric_cols] = null_df[numeric_cols].apply(regression_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Number of Outliers</th>\n",
       "      <th>Outlier Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>adults</td>\n",
       "      <td>31102</td>\n",
       "      <td>31.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>change_rev</td>\n",
       "      <td>26669</td>\n",
       "      <td>26.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>income</td>\n",
       "      <td>18923</td>\n",
       "      <td>18.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>threeway_Mean</td>\n",
       "      <td>17901</td>\n",
       "      <td>17.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cc_mou_Mean</td>\n",
       "      <td>12750</td>\n",
       "      <td>12.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>drop_dat_Mean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>blck_dat_Mean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unan_dat_Mean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Customer_ID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>num_ppl_household</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Number of Outliers  Outlier Percentage\n",
       "71             adults               31102              31.102\n",
       "10         change_rev               26669              26.669\n",
       "72             income               18923              18.923\n",
       "27      threeway_Mean               17901              17.901\n",
       "25        cc_mou_Mean               12750              12.750\n",
       "..                ...                 ...                 ...\n",
       "12      drop_dat_Mean                   0               0.000\n",
       "14      blck_dat_Mean                   0               0.000\n",
       "16      unan_dat_Mean                   0               0.000\n",
       "74        Customer_ID                   0               0.000\n",
       "75  num_ppl_household                   0               0.000\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_outliers(outliers_df, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn outlier imputation - start with lower k \n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "knn_outlier_df = outliers_df.copy()\n",
    "knn_outlier_df[numeric_cols] = imputer.fit_transform(knn_outlier_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>change_mou</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>num_ppl_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.997500</td>\n",
       "      <td>219.250000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-157.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.492500</td>\n",
       "      <td>482.750000</td>\n",
       "      <td>37.425000</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>9.10000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.410104</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>1000002.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.990000</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>16.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>534.747973</td>\n",
       "      <td>1000003.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>534.744754</td>\n",
       "      <td>1000004.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.230000</td>\n",
       "      <td>570.500000</td>\n",
       "      <td>71.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>1000005.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>58.719985</td>\n",
       "      <td>513.559937</td>\n",
       "      <td>46.179136</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>41.072247</td>\n",
       "      <td>13.55956</td>\n",
       "      <td>13.295062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047057</td>\n",
       "      <td>-13.933818</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>773.000000</td>\n",
       "      <td>1099996.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>58.719985</td>\n",
       "      <td>513.559937</td>\n",
       "      <td>46.179136</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>41.072247</td>\n",
       "      <td>13.55956</td>\n",
       "      <td>13.295062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047057</td>\n",
       "      <td>-13.933818</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>1099997.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>58.719985</td>\n",
       "      <td>513.559937</td>\n",
       "      <td>46.179136</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>41.072247</td>\n",
       "      <td>13.55956</td>\n",
       "      <td>13.295062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047057</td>\n",
       "      <td>-13.933818</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>1099998.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>58.719985</td>\n",
       "      <td>513.559937</td>\n",
       "      <td>46.179136</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>41.072247</td>\n",
       "      <td>13.55956</td>\n",
       "      <td>13.295062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047058</td>\n",
       "      <td>-13.933818</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1099999.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>58.719985</td>\n",
       "      <td>513.559937</td>\n",
       "      <td>46.179136</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>41.072247</td>\n",
       "      <td>13.55956</td>\n",
       "      <td>13.295062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047058</td>\n",
       "      <td>-13.933818</td>\n",
       "      <td>...</td>\n",
       "      <td>H</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>N</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rev_Mean    mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0      23.997500  219.250000    22.500000  0.247500     0.000000      0.00000   \n",
       "1      57.492500  482.750000    37.425000  0.247500    22.750000      9.10000   \n",
       "2      16.990000   10.250000    16.990000  0.000000     0.000000      0.00000   \n",
       "3      38.000000    7.500000    38.000000  0.000000     0.000000      0.00000   \n",
       "4      55.230000  570.500000    71.980000  0.000000     0.000000      0.00000   \n",
       "...          ...         ...          ...       ...          ...          ...   \n",
       "99995  58.719985  513.559937    46.179136  0.888828    41.072247     13.55956   \n",
       "99996  58.719985  513.559937    46.179136  0.888828    41.072247     13.55956   \n",
       "99997  58.719985  513.559937    46.179136  0.888828    41.072247     13.55956   \n",
       "99998  58.719985  513.559937    46.179136  0.888828    41.072247     13.55956   \n",
       "99999  58.719985  513.559937    46.179136  0.888828    41.072247     13.55956   \n",
       "\n",
       "       vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  ethnic  kid0_2  \\\n",
       "0         0.000000          0.0   0.000000 -157.250000  ...       N       U   \n",
       "1         9.100000          0.0   0.000000  -10.410104  ...       Z       U   \n",
       "2         0.000000          0.0   0.000000   -4.250000  ...       N       U   \n",
       "3         0.000000          0.0   0.000000   -1.500000  ...       U       Y   \n",
       "4         0.000000          0.0   0.000000   38.500000  ...       I       U   \n",
       "...            ...          ...        ...         ...  ...     ...     ...   \n",
       "99995    13.295062          0.0   0.047057  -13.933818  ...       S       U   \n",
       "99996    13.295062          0.0   0.047057  -13.933818  ...       N       U   \n",
       "99997    13.295062          0.0   0.047057  -13.933818  ...       U       Y   \n",
       "99998    13.295062          0.0   0.047058  -13.933818  ...       S       U   \n",
       "99999    13.295062          0.0   0.047058  -13.933818  ...       H       U   \n",
       "\n",
       "       kid3_5  kid6_10  kid11_15  kid16_17  creditcd     eqpdays  Customer_ID  \\\n",
       "0           U        U         U         U         Y  361.000000    1000001.0   \n",
       "1           U        U         U         U         Y  240.000000    1000002.0   \n",
       "2           Y        U         U         U         Y  534.747973    1000003.0   \n",
       "3           U        U         U         U         Y  534.744754    1000004.0   \n",
       "4           U        U         U         U         Y  434.000000    1000005.0   \n",
       "...       ...      ...       ...       ...       ...         ...          ...   \n",
       "99995       U        U         Y         U         Y  773.000000    1099996.0   \n",
       "99996       U        Y         Y         Y         Y  835.000000    1099997.0   \n",
       "99997       Y        U         U         U         N  433.000000    1099998.0   \n",
       "99998       U        U         U         U         N   75.000000    1099999.0   \n",
       "99999       U        U         U         U         N    5.000000    1100000.0   \n",
       "\n",
       "       num_ppl_household  \n",
       "0                    1.0  \n",
       "1                    1.0  \n",
       "2                    3.0  \n",
       "3                    5.0  \n",
       "4                    1.0  \n",
       "...                  ...  \n",
       "99995                6.0  \n",
       "99996                6.0  \n",
       "99997                3.0  \n",
       "99998                2.0  \n",
       "99999                2.0  \n",
       "\n",
       "[100000 rows x 99 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Number of Outliers</th>\n",
       "      <th>Outlier Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>adults</td>\n",
       "      <td>31102</td>\n",
       "      <td>31.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>change_rev</td>\n",
       "      <td>26669</td>\n",
       "      <td>26.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>income</td>\n",
       "      <td>18923</td>\n",
       "      <td>18.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>threeway_Mean</td>\n",
       "      <td>17901</td>\n",
       "      <td>17.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cc_mou_Mean</td>\n",
       "      <td>12750</td>\n",
       "      <td>12.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>drop_dat_Mean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>blck_dat_Mean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unan_dat_Mean</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Customer_ID</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>num_ppl_household</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature  Number of Outliers  Outlier Percentage\n",
       "71             adults               31102              31.102\n",
       "10         change_rev               26669              26.669\n",
       "72             income               18923              18.923\n",
       "27      threeway_Mean               17901              17.901\n",
       "25        cc_mou_Mean               12750              12.750\n",
       "..                ...                 ...                 ...\n",
       "12      drop_dat_Mean                   0               0.000\n",
       "14      blck_dat_Mean                   0               0.000\n",
       "16      unan_dat_Mean                   0               0.000\n",
       "74        Customer_ID                   0               0.000\n",
       "75  num_ppl_household                   0               0.000\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_outliers(knn_outlier_df, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.to_csv('../data/processed/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
